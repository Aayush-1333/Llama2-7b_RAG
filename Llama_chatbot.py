from openai import OpenAI

OPEN_AI_KEY = "EMPTY"
BASE_URL = "http://localhost:8000/v1"


class Llama2_ChatBot:
    
    def __init__(self) -> None:
        """Constructor of the class"""
        self.__client = OpenAI(
            api_key=OPEN_AI_KEY,
            base_url=BASE_URL
        )
        
    def get_chat_response(self, prompt: str) -> str:
        """This method returns the response generated by the LLM based on user's given query

        Args:
            prompt (str): User query in string

        Returns:
            str: response generated by the model
        """
        chat_response = self.__client.chat.completions.create(
            model="TheBloke/Llama-2-7B-Chat-AWQ",
            temperature=0.9,
            messages=[
                {"role": "system", "content": "You are a helpful assistant"},
                {"role": "user", "content": prompt},
            ]
        )

        chat_response = chat_response.choices[0].message.content
        return chat_response
